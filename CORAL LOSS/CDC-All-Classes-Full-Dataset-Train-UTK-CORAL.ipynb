{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CDC-All-Classes-Full-Dataset-Train-UTK-CORAL.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"In3HxBUKZ06F","executionInfo":{"status":"ok","timestamp":1631472687181,"user_tz":-360,"elapsed":697,"user":{"displayName":"CSE499 Polymorphs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18372209323855850046"}},"outputId":"b4dbec5a-510c-4bbb-ab40-952bf048fe22"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep 12 18:51:26 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    33W / 250W |    913MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"Eo6Sqav1Z06F"},"source":["import os\n","import time\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","from torch.optim import lr_scheduler\n","\n","from torchvision import transforms\n","from PIL import Image\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","import torchvision.models as models\n","from collections import OrderedDict\n","torch.autograd.set_detect_anomaly(True)\n","import copy\n","import datetime\n","import pytz\n","\n","import math\n","import torch.utils.model_zoo as model_zoo\n","from torch.nn import Parameter\n","import pdb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ur4hcZZ0Z06G","executionInfo":{"status":"ok","timestamp":1631472687629,"user_tz":-360,"elapsed":27,"user":{"displayName":"CSE499 Polymorphs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18372209323855850046"}},"outputId":"1003b6ff-2d2e-4d43-c466-a73648d3c0a4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"8YZbdh-RZ06G"},"source":["TRAIN_CSV_PATH = '/content/drive/MyDrive/CSE465/datasets/UTKFace/csv/UTKFace_1_101-all-classes.csv'\n","IMAGE_PATH = '/content/drive/MyDrive/CSE465/datasets/UTKFace/UTKFace-images'\n","\n","RANDOM_SEED = 42\n","MODEL_NAME = \"All-classes-Full-UTK-CORAL_CDCNpp\"\n","PATH = \"/content/drive/MyDrive/CSE465/Models_and_Logs/\" + MODEL_NAME\n","\n","GRAYSCALE = False\n","NUM_CLASSES = 101\n","BATCH_SIZE = 32\n","EPOCHS = 64 #200\n","learning_rate = 0.0005\n","NUM_WORKERS = 0\n","IMP_WEIGHT = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F8EMe8hYZ06G"},"source":["# GPU or CPU\n","DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VAv_aAhZ06G"},"source":["# Log File\n","if not os.path.exists(PATH): os.mkdir(PATH)\n","LOGFILE = os.path.join(PATH, 'training.log')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gJkXIwrNZ06G"},"source":["header = []\n","timezone = pytz.timezone('Asia/Dhaka')\n","header.append(f'\\n\\n\\nLast Run: {datetime.datetime.now(timezone)}')\n","header.append(f'PyTorch Version: {torch.__version__}')\n","header.append(f'CUDA device available: {torch.cuda.is_available()}')\n","header.append(f'Using CUDA device: {DEVICE}')\n","header.append(f'Random Seed: {RANDOM_SEED}')\n","header.append(f'NUM WORKERS: {NUM_WORKERS}')\n","header.append(f'Model Name: {MODEL_NAME}')\n","header.append(f'Output Path: {PATH}')\n","header.append(f'-------------------HyperParameters---------------')\n","header.append(f'No. of Classes: {NUM_CLASSES}')\n","header.append(f'Batch size: {BATCH_SIZE}')\n","header.append(f'Grayscale: {GRAYSCALE}')\n","header.append(f'Learning Rate: {learning_rate}')\n","header.append(f'Epochs: {EPOCHS}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UKAf6GdiCKNK","executionInfo":{"status":"ok","timestamp":1631472687632,"user_tz":-360,"elapsed":24,"user":{"displayName":"CSE499 Polymorphs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18372209323855850046"}},"outputId":"6d25473e-4080-4fee-921f-a8e165c298a9"},"source":["for entry in header:\n","  print(entry)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n","Last Run: 2021-09-13 00:51:27.615321+06:00\n","PyTorch Version: 1.9.0+cu102\n","CUDA device available: True\n","Using CUDA device: cuda\n","Random Seed: 42\n","NUM WORKERS: 0\n","Model Name: All-classes-Full-UTK-CORAL_CDCNpp\n","Output Path: /content/drive/MyDrive/CSE465/Models_and_Logs/All-classes-Full-UTK-CORAL_CDCNpp\n","-------------------HyperParameters---------------\n","No. of Classes: 101\n","Batch size: 32\n","Grayscale: False\n","Learning Rate: 0.0005\n","Epochs: 200\n"]}]},{"cell_type":"code","metadata":{"id":"ta1NzR7sZ06H"},"source":["with open(LOGFILE, 'a') as f:\n","    for entry in header:\n","        f.write(f'{entry}\\n')\n","        f.flush()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjEDWKU6cCVx","executionInfo":{"status":"ok","timestamp":1631472687633,"user_tz":-360,"elapsed":21,"user":{"displayName":"CSE499 Polymorphs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18372209323855850046"}},"outputId":"68d62e8e-5fa4-4140-c4be-b15e24135f27"},"source":["df = pd.read_csv(TRAIN_CSV_PATH)\n","labels = df['label'].values\n","del df\n","labels = torch.tensor(labels, dtype=torch.float)\n","print(labels.size())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([23689])\n"]}]},{"cell_type":"code","metadata":{"id":"NtQ3SyApbyou"},"source":["def task_importance_weights(label_array):\n","    uniq = torch.unique(label_array)\n","    num_examples = label_array.size(0)\n","\n","    # m = torch.zeros(uniq.shape[0])\n","    m = torch.zeros(int(torch.max(labels).item())) #tensor of 101 zeros\n","\n","    for i, t in enumerate(torch.arange(torch.min(uniq), torch.max(uniq)+1)):\n","        m_k = torch.max(torch.tensor([label_array[label_array > t].size(0), \n","                                      num_examples - label_array[label_array > t].size(0)]))\n","        m[i] = torch.sqrt(m_k.float())\n","\n","    imp = m/torch.max(m)\n","    return imp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"baSlyhuhcFY5"},"source":["# Data-specific scheme\n","if not IMP_WEIGHT:\n","    imp = torch.ones(NUM_CLASSES, dtype=torch.float)\n","elif IMP_WEIGHT == 1:\n","    imp = task_importance_weights(labels)\n","    imp = imp[0:NUM_CLASSES]\n","else:\n","    raise ValueError('Incorrect importance weight parameter.')\n","imp = imp.to(DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M2L1OGd0Z06I"},"source":[" **Dataset**"]},{"cell_type":"code","metadata":{"id":"usJCc3sJZ06I"},"source":["class UTKFaceDataset(Dataset):\n","    \"\"\"Custom Dataset for loading UTKFace face images\"\"\"\n","\n","    def __init__(self, csv_path, img_dir, transform=None, items=None):\n","        df = pd.read_csv(csv_path)\n","        df['index'] = range(0, len(df))\n","        df = df.set_index('index')\n","\n","        if items:\n","          df=df[:items]\n","        self.img_dir = img_dir\n","        self.csv_path = csv_path\n","        self.img_names = df['file'].values\n","        self.y = df['label'].values\n","        self.age = df['age'].values\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img = Image.open(os.path.join(self.img_dir, self.img_names[index]))\n","        # img = img.convert('RGB')\n","        \n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        label = self.y[index]\n","        levels = [1]*label + [0]*(NUM_CLASSES - label) #converting labels to levels..so if age is 22, 22 ones and (79-22) zeros, since total class is 101\n","        levels = torch.tensor(levels, dtype=torch.float32)\n","\n","        return img, label, levels\n","        \n","    def __len__(self):\n","        return self.y.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7AuQwbC4EP33"},"source":["custom_transform_train = transforms.Compose([transforms.Resize((256, 256)),\n","                                       transforms.RandomCrop((224, 224)),\n","                                       transforms.ToTensor(),\n","                                       ])\n","\n","train_dataset = UTKFaceDataset(csv_path=TRAIN_CSV_PATH,\n","                               img_dir=IMAGE_PATH,\n","                               transform=custom_transform_train,\n","                               items = None\n","                               )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JWGfZNbrZ06J"},"source":["**Dataset Entity Distribution Analysis**"]},{"cell_type":"code","metadata":{"id":"HaOqZXPBZ06J"},"source":["def dataset_analysis(d):\n","  counter_label = Counter(np.sort(d.y))\n","  counter_age = Counter(np.sort(d.age))\n","\n","  plt.scatter(counter_age.keys(), counter_age.values(), s=10, c='black')\n","  plt.xlabel('Ages')\n","  plt.ylabel('Num of images per Age')\n","  plt.title('Entity Distribution Analysis')\n","  plt.grid()\n","  plt.show()\n","  \n","  print(\"label\\t\\tAge\\t\\tCount\")\n","  for (label, key, value) in zip(counter_label.keys(), counter_age.keys(), counter_age.values()):\n","    print(label,'\\t\\t',key,'\\t\\t', value)\n","\n","  print(torch.from_numpy(d.age).bincount())\n","  print('length of the dataset is: ', len(d))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"5Er-_XKlZ06J","executionInfo":{"status":"ok","timestamp":1631472688129,"user_tz":-360,"elapsed":509,"user":{"displayName":"CSE499 Polymorphs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18372209323855850046"}},"outputId":"9de4e514-61c8-4fb0-a5e3-bec4a2f4635a"},"source":["dataset_analysis(train_dataset)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["label\t\tAge\t\tCount\n","1 \t\t 1 \t\t 1123\n","2 \t\t 2 \t\t 482\n","3 \t\t 3 \t\t 289\n","4 \t\t 4 \t\t 273\n","5 \t\t 5 \t\t 196\n","6 \t\t 6 \t\t 131\n","7 \t\t 7 \t\t 139\n","8 \t\t 8 \t\t 263\n","9 \t\t 9 \t\t 166\n","10 \t\t 10 \t\t 156\n","11 \t\t 11 \t\t 65\n","12 \t\t 12 \t\t 130\n","13 \t\t 13 \t\t 81\n","14 \t\t 14 \t\t 157\n","15 \t\t 15 \t\t 177\n","16 \t\t 16 \t\t 247\n","17 \t\t 17 \t\t 158\n","18 \t\t 18 \t\t 262\n","19 \t\t 19 \t\t 98\n","20 \t\t 20 \t\t 284\n","21 \t\t 21 \t\t 346\n","22 \t\t 22 \t\t 395\n","23 \t\t 23 \t\t 426\n","24 \t\t 24 \t\t 859\n","25 \t\t 25 \t\t 734\n","26 \t\t 26 \t\t 2197\n","27 \t\t 27 \t\t 615\n","28 \t\t 28 \t\t 918\n","29 \t\t 29 \t\t 570\n","30 \t\t 30 \t\t 724\n","31 \t\t 31 \t\t 350\n","32 \t\t 32 \t\t 664\n","33 \t\t 33 \t\t 143\n","34 \t\t 34 \t\t 409\n","35 \t\t 35 \t\t 880\n","36 \t\t 36 \t\t 483\n","37 \t\t 37 \t\t 293\n","38 \t\t 38 \t\t 325\n","39 \t\t 39 \t\t 266\n","40 \t\t 40 \t\t 526\n","41 \t\t 41 \t\t 132\n","42 \t\t 42 \t\t 266\n","43 \t\t 43 \t\t 157\n","44 \t\t 44 \t\t 100\n","45 \t\t 45 \t\t 440\n","46 \t\t 46 \t\t 153\n","47 \t\t 47 \t\t 170\n","48 \t\t 48 \t\t 153\n","49 \t\t 49 \t\t 148\n","50 \t\t 50 \t\t 381\n","51 \t\t 51 \t\t 138\n","52 \t\t 52 \t\t 232\n","53 \t\t 53 \t\t 241\n","54 \t\t 54 \t\t 353\n","55 \t\t 55 \t\t 268\n","56 \t\t 56 \t\t 236\n","57 \t\t 57 \t\t 97\n","58 \t\t 58 \t\t 271\n","59 \t\t 59 \t\t 82\n","60 \t\t 60 \t\t 293\n","61 \t\t 61 \t\t 161\n","62 \t\t 62 \t\t 125\n","63 \t\t 63 \t\t 103\n","64 \t\t 64 \t\t 50\n","65 \t\t 65 \t\t 259\n","66 \t\t 66 \t\t 77\n","67 \t\t 67 \t\t 94\n","68 \t\t 68 \t\t 100\n","69 \t\t 69 \t\t 56\n","70 \t\t 70 \t\t 147\n","71 \t\t 71 \t\t 33\n","72 \t\t 72 \t\t 98\n","73 \t\t 73 \t\t 63\n","74 \t\t 74 \t\t 32\n","75 \t\t 75 \t\t 148\n","76 \t\t 76 \t\t 58\n","77 \t\t 77 \t\t 28\n","78 \t\t 78 \t\t 69\n","79 \t\t 79 \t\t 23\n","80 \t\t 80 \t\t 133\n","81 \t\t 81 \t\t 22\n","82 \t\t 82 \t\t 40\n","83 \t\t 83 \t\t 18\n","84 \t\t 84 \t\t 24\n","85 \t\t 85 \t\t 155\n","86 \t\t 86 \t\t 35\n","87 \t\t 87 \t\t 10\n","88 \t\t 88 \t\t 34\n","89 \t\t 89 \t\t 33\n","90 \t\t 90 \t\t 82\n","91 \t\t 91 \t\t 2\n","92 \t\t 92 \t\t 13\n","93 \t\t 93 \t\t 5\n","95 \t\t 95 \t\t 9\n","96 \t\t 96 \t\t 17\n","99 \t\t 99 \t\t 9\n","100 \t\t 100 \t\t 11\n","101 \t\t 101 \t\t 2\n","tensor([   0, 1123,  482,  289,  273,  196,  131,  139,  263,  166,  156,   65,\n","         130,   81,  157,  177,  247,  158,  262,   98,  284,  346,  395,  426,\n","         859,  734, 2197,  615,  918,  570,  724,  350,  664,  143,  409,  880,\n","         483,  293,  325,  266,  526,  132,  266,  157,  100,  440,  153,  170,\n","         153,  148,  381,  138,  232,  241,  353,  268,  236,   97,  271,   82,\n","         293,  161,  125,  103,   50,  259,   77,   94,  100,   56,  147,   33,\n","          98,   63,   32,  148,   58,   28,   69,   23,  133,   22,   40,   18,\n","          24,  155,   35,   10,   34,   33,   82,    2,   13,    5,    0,    9,\n","          17,    0,    0,    9,   11,    2])\n","length of the dataset is:  23689\n"]}]},{"cell_type":"markdown","metadata":{"id":"NQGi7g2_Z06J"},"source":["**Dataset Loader**"]},{"cell_type":"code","metadata":{"id":"ybkBkOdJZ06J"},"source":["train_loader = DataLoader(dataset=train_dataset,\n","                          batch_size=BATCH_SIZE,\n","                          shuffle=True,\n","                          num_workers=NUM_WORKERS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50rz-0Q6Z06K","executionInfo":{"status":"ok","timestamp":1631472688132,"user_tz":-360,"elapsed":15,"user":{"displayName":"CSE499 Polymorphs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18372209323855850046"}},"outputId":"48acc787-5abe-4755-cc86-37df4b676b76"},"source":["len(train_loader)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["741"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"coO69YfMZ06L"},"source":["**Model**"]},{"cell_type":"code","metadata":{"id":"ONmxvp5_BnG1"},"source":["class Conv2d_cd(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,\n","                 padding=1, dilation=1, groups=1, bias=False, theta=0.7):\n","\n","        super(Conv2d_cd, self).__init__() \n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n","        self.theta = theta\n","\n","    def forward(self, x):\n","        out_normal = self.conv(x)\n","\n","        if math.fabs(self.theta - 0.0) < 1e-8:\n","            return out_normal \n","        else:\n","            #pdb.set_trace()\n","            [C_out,C_in, kernel_size,kernel_size] = self.conv.weight.shape\n","            kernel_diff = self.conv.weight.sum(2).sum(2)\n","            kernel_diff = kernel_diff[:, :, None, None]\n","            out_diff = F.conv2d(input=x, weight=kernel_diff, bias=self.conv.bias, stride=self.conv.stride, padding=0, groups=self.conv.groups)\n","\n","            return out_normal - self.theta * out_diff\n","        \n","class SpatialAttention(nn.Module):\n","    def __init__(self, kernel = 3):\n","        super(SpatialAttention, self).__init__()\n","\n","\n","        self.conv1 = nn.Conv2d(2, 1, kernel_size=kernel, padding=kernel//2, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = torch.mean(x, dim=1, keepdim=True)\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","        x = torch.cat([avg_out, max_out], dim=1)\n","        x = self.conv1(x)\n","        \n","        return self.sigmoid(x)\n","\n","class CDCN(nn.Module):\n","\n","    def __init__(self, basic_conv=Conv2d_cd, theta=0.7):   \n","        super(CDCN, self).__init__()\n","        \n","        \n","        self.conv1 = nn.Sequential(\n","            basic_conv(3, 64, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),    \n","        )\n","        \n","        self.Block1 = nn.Sequential(\n","            basic_conv(64, 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),   \n","            basic_conv(128, 196, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(196),\n","            nn.ReLU(),  \n","            basic_conv(196, 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),   \n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            \n","        )\n","        \n","        self.Block2 = nn.Sequential(\n","            basic_conv(128, 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),   \n","            basic_conv(128, 196, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(196),\n","            nn.ReLU(),  \n","            basic_conv(196, 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),  \n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","        )\n","        \n","        self.Block3 = nn.Sequential(\n","            basic_conv(128, 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),   \n","            basic_conv(128, 196, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(196),\n","            nn.ReLU(),  \n","            basic_conv(196, 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),   \n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","        )\n","        \n","        self.lastconv1 = nn.Sequential(\n","            basic_conv(128*3, 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),    \n","        )\n","        \n","        self.lastconv2 = nn.Sequential(\n","            basic_conv(128, 64, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),    \n","        )\n","        \n","        self.lastconv3 = nn.Sequential(\n","            basic_conv(64, 1, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.ReLU(),    \n","        )   \n","        \n","        self.downsample32x32 = nn.Upsample(size=(32, 32), mode='bilinear')\n","        \n","        \"\"\"newly added start\"\"\"\n","        self.fc_1024_512 = nn.Linear(in_features=1024, out_features=512)\n","        self.fc_512_1 = nn.Linear(in_features=512, out_features=1, bias=False)\n","        self.linear_1_bias = nn.Parameter(torch.zeros(NUM_CLASSES).float())\n","        \"\"\"newly added end\"\"\"\n","\n"," \n","    def forward(self, x):\t    \t# x [3, 256, 256]\n","        \n","        x_input = x\n","        x = self.conv1(x)\t\t   \n","        \n","        x_Block1 = self.Block1(x)\t    \t    \t# x [128, 128, 128]\n","        x_Block1_32x32 = self.downsample32x32(x_Block1)   # x [128, 32, 32]  \n","        \n","        x_Block2 = self.Block2(x_Block1)\t    # x [128, 64, 64]\t  \n","        x_Block2_32x32 = self.downsample32x32(x_Block2)   # x [128, 32, 32]  \n","        \n","        x_Block3 = self.Block3(x_Block2)\t    # x [128, 32, 32]  \t\n","        x_Block3_32x32 = self.downsample32x32(x_Block3)   # x [128, 32, 32]  \n","        \n","        x_concat = torch.cat((x_Block1_32x32,x_Block2_32x32,x_Block3_32x32), dim=1)    # x [128*3, 32, 32]  \n","        \n","        #pdb.set_trace()\n","        \n","        x = self.lastconv1(x_concat)    # x [128, 32, 32] \n","        x = self.lastconv2(x)    # x [64, 32, 32] \n","        x = self.lastconv3(x)    # x [1, 32, 32] \n","        \n","        x = x.squeeze(1)\n","\n","        \"\"\"newly added start\"\"\"\n","        x = x.view(x.size(0), -1)\n","        x = self.fc_1024_512(x)\n","        x = F.relu(x)\n","        logits = self.fc_512_1(x)\n","        logits = logits + self.linear_1_bias\n","        probas = torch.sigmoid(logits)\n","\n","        return logits, probas\n","        \"\"\"newly added end\"\"\"\n","        \n","        # return map_x, x_concat, x_Block1, x_Block2, x_Block3, x_input\n","\n","\n","class CDCNpp(nn.Module):\n","\n","    def __init__(self, basic_conv=Conv2d_cd, theta=0.7 ):   \n","        super(CDCNpp, self).__init__()\n","        \n","        \n","        self.conv1 = nn.Sequential(\n","            basic_conv(3, 64, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),    \n","            \n","        )\n","        \n","        self.Block1 = nn.Sequential(\n","            basic_conv(64, 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),  \n","            \n","            basic_conv(128, int(128*1.6), kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(int(128*1.6)),\n","            nn.ReLU(),  \n","            basic_conv(int(128*1.6), 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(), \n","            \n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            \n","        )\n","        \n","        self.Block2 = nn.Sequential(\n","            basic_conv(128, int(128*1.2), kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(int(128*1.2)),\n","            nn.ReLU(),  \n","            basic_conv(int(128*1.2), 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),  \n","            basic_conv(128, int(128*1.4), kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(int(128*1.4)),\n","            nn.ReLU(),  \n","            basic_conv(int(128*1.4), 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),  \n","            \n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","        )\n","        \n","        self.Block3 = nn.Sequential(\n","            basic_conv(128, 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(), \n","            basic_conv(128, int(128*1.2), kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(int(128*1.2)),\n","            nn.ReLU(),  \n","            basic_conv(int(128*1.2), 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(), \n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","        )\n","        \n","        # Original\n","        \n","        self.lastconv1 = nn.Sequential(\n","            basic_conv(128*3, 128, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            basic_conv(128, 1, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.ReLU(),    \n","        )\n","        \n","      \n","        self.sa1 = SpatialAttention(kernel = 7)\n","        self.sa2 = SpatialAttention(kernel = 5)\n","        self.sa3 = SpatialAttention(kernel = 3)\n","        self.downsample32x32 = nn.Upsample(size=(32, 32), mode='bilinear')\n","\n","        \"\"\"newly added start\"\"\"\n","        self.fc_1024_512 = nn.Linear(in_features=1024, out_features=512)\n","        self.fc_512_1 = nn.Linear(in_features=512, out_features=1, bias=False)\n","        self.linear_1_bias = nn.Parameter(torch.zeros(NUM_CLASSES).float())\n","        \"\"\"newly added end\"\"\"\n","\n"," \n","    def forward(self, x):\t    \t# x [3, 256, 256]\n","        \n","        x_input = x\n","        x = self.conv1(x)\t\t   \n","        \n","        x_Block1 = self.Block1(x)\t    \t    \t\n","        attention1 = self.sa1(x_Block1)\n","        x_Block1_SA = attention1 * x_Block1\n","        x_Block1_32x32 = self.downsample32x32(x_Block1_SA)   \n","        \n","        x_Block2 = self.Block2(x_Block1)\t    \n","        attention2 = self.sa2(x_Block2)  \n","        x_Block2_SA = attention2 * x_Block2\n","        x_Block2_32x32 = self.downsample32x32(x_Block2_SA)  \n","        \n","        x_Block3 = self.Block3(x_Block2)\t    \n","        attention3 = self.sa3(x_Block3)  \n","        x_Block3_SA = attention3 * x_Block3\t\n","        x_Block3_32x32 = self.downsample32x32(x_Block3_SA)   \n","        \n","        x_concat = torch.cat((x_Block1_32x32,x_Block2_32x32,x_Block3_32x32), dim=1)    \n","        \n","        #pdb.set_trace()\n","        \n","        x = self.lastconv1(x_concat)\n","        x = x.squeeze(1)\n","\n","        \"\"\"newly added start\"\"\"\n","        x = x.view(x.size(0), -1)\n","        x = self.fc_1024_512(x)\n","        x = F.relu(x)\n","        logits = self.fc_512_1(x)\n","        logits = logits + self.linear_1_bias\n","        probas = torch.sigmoid(logits)\n","\n","        return logits, probas\n","        \"\"\"newly added end\"\"\"\n","        \n","        # return map_x, x_concat, attention1, attention2, attention3, x_input"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"14tcBAS4-RPW"},"source":["**Initialise Model & Optimizer**"]},{"cell_type":"code","metadata":{"id":"Ekt7IOLSAIiQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631472688784,"user_tz":-360,"elapsed":18,"user":{"displayName":"CSE499 Polymorphs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18372209323855850046"}},"outputId":"4ffab861-646e-4ffb-e980-34c013a7d9cc"},"source":["torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed(RANDOM_SEED)\n","# model = CDCN()\n","model = CDCNpp()\n","\n","params_to_update = model.parameters()\n","print(\"Params to learn:\")\n","for name,param in model.named_parameters(): print(\"\\t\",name)\n","model.to(DEVICE)\n","\n","optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Params to learn:\n","\t linear_1_bias\n","\t conv1.0.conv.weight\n","\t conv1.1.weight\n","\t conv1.1.bias\n","\t Block1.0.conv.weight\n","\t Block1.1.weight\n","\t Block1.1.bias\n","\t Block1.3.conv.weight\n","\t Block1.4.weight\n","\t Block1.4.bias\n","\t Block1.6.conv.weight\n","\t Block1.7.weight\n","\t Block1.7.bias\n","\t Block2.0.conv.weight\n","\t Block2.1.weight\n","\t Block2.1.bias\n","\t Block2.3.conv.weight\n","\t Block2.4.weight\n","\t Block2.4.bias\n","\t Block2.6.conv.weight\n","\t Block2.7.weight\n","\t Block2.7.bias\n","\t Block2.9.conv.weight\n","\t Block2.10.weight\n","\t Block2.10.bias\n","\t Block3.0.conv.weight\n","\t Block3.1.weight\n","\t Block3.1.bias\n","\t Block3.3.conv.weight\n","\t Block3.4.weight\n","\t Block3.4.bias\n","\t Block3.6.conv.weight\n","\t Block3.7.weight\n","\t Block3.7.bias\n","\t lastconv1.0.conv.weight\n","\t lastconv1.1.weight\n","\t lastconv1.1.bias\n","\t lastconv1.3.conv.weight\n","\t sa1.conv1.weight\n","\t sa2.conv1.weight\n","\t sa3.conv1.weight\n","\t fc_1024_512.weight\n","\t fc_1024_512.bias\n","\t fc_512_1.weight\n"]}]},{"cell_type":"code","metadata":{"id":"pg2O85F2FJM4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631472688785,"user_tz":-360,"elapsed":14,"user":{"displayName":"CSE499 Polymorphs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18372209323855850046"}},"outputId":"3bc8e2df-f8fe-4038-c7c0-a128a14679da"},"source":["print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CDCNpp(\n","  (conv1): Sequential(\n","    (0): Conv2d_cd(\n","      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (Block1): Sequential(\n","    (0): Conv2d_cd(\n","      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Conv2d_cd(\n","      (conv): Conv2d(128, 204, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): Conv2d_cd(\n","      (conv): Conv2d(204, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU()\n","    (9): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (Block2): Sequential(\n","    (0): Conv2d_cd(\n","      (conv): Conv2d(128, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Conv2d_cd(\n","      (conv): Conv2d(153, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): Conv2d_cd(\n","      (conv): Conv2d(128, 179, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (7): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU()\n","    (9): Conv2d_cd(\n","      (conv): Conv2d(179, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): ReLU()\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (Block3): Sequential(\n","    (0): Conv2d_cd(\n","      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Conv2d_cd(\n","      (conv): Conv2d(128, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (4): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): Conv2d_cd(\n","      (conv): Conv2d(153, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU()\n","    (9): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (lastconv1): Sequential(\n","    (0): Conv2d_cd(\n","      (conv): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Conv2d_cd(\n","      (conv): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (4): ReLU()\n","  )\n","  (sa1): SpatialAttention(\n","    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    (sigmoid): Sigmoid()\n","  )\n","  (sa2): SpatialAttention(\n","    (conv1): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","    (sigmoid): Sigmoid()\n","  )\n","  (sa3): SpatialAttention(\n","    (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (sigmoid): Sigmoid()\n","  )\n","  (downsample32x32): Upsample(size=(32, 32), mode=bilinear)\n","  (fc_1024_512): Linear(in_features=1024, out_features=512, bias=True)\n","  (fc_512_1): Linear(in_features=512, out_features=1, bias=False)\n",")\n"]}]},{"cell_type":"code","metadata":{"id":"6vDfpvsze0Fu"},"source":["#logsigmoid range -infinity to 0\n","def cost_fn(logits, levels, imp):\n","    val = (-torch.sum((F.logsigmoid(logits)*levels\n","                      + (F.logsigmoid(logits) - logits)*(1-levels))*imp,\n","           dim=1))\n","    return torch.mean(val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CS2A-nZWZ06N"},"source":["`torch.max()` `returns` highest elements along the dimension and indexes of highest values, here we are only interested to the indexes of highest elements"]},{"cell_type":"code","metadata":{"id":"uoLv0POjZ06N"},"source":["def calculate_correct_preds(probas, targets):\n","  return torch.sum(torch.max(probas, dim = 1)[1] == targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6IJa6V3Z06N"},"source":["def compute_acc(total_num_correct_preds, num_examples):\n","  return format((total_num_correct_preds/num_examples) * 100.0, '.3f')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QZRfUiv9Z06O"},"source":["**Training**\n","\n","PyTorch Normally add the previously calculated gradient with the current calculated gradient and then updates the weight. But here we don't want it. That's why we made the previously calculted gradient zero while calculating a new one with `optimizer.zero_grad()`"]},{"cell_type":"code","metadata":{"id":"PG0x_gU8Z06O"},"source":["start_time = time.time()\n","\n","for epoch in tqdm(range(EPOCHS)):\n","  train_total_num_correct_preds = train_num_examples = 0\n","\n","  model.train()\n","  train_mae=0.0\n","  for batch_idx, (features, targets, levels) in enumerate(tqdm(train_loader)):\n","\n","    features = features.to(DEVICE)\n","    targets = targets.to(DEVICE)\n","    levels = levels.to(DEVICE)\n","\n","    # FORWARD AND BACK PROP\n","    logits, probas = model(features)\n","    cost = cost_fn(logits, levels, imp)\n","    predict_levels = probas > 0.5\n","    predicted_labels = torch.sum(predict_levels, dim=1)\n","    num_correct_preds = torch.sum(predicted_labels == targets)\n","\n","    optimizer.zero_grad()\n","\n","    cost.backward()\n","\n","    # UPDATE MODEL PARAMETERS\n","    optimizer.step()\n","\n","    train_total_num_correct_preds += num_correct_preds\n","    train_num_examples += targets.size(0) \n","    train_mae += torch.sum(torch.abs(predicted_labels - targets))\n","      \n","  train_mae = train_mae/train_num_examples\n","  # LOGGING\n","  print(f'Correct Train Preds: {train_total_num_correct_preds}')\n","  training_acc = compute_acc(train_total_num_correct_preds, train_num_examples)\n","\n","  time_elapsed = format((time.time() - start_time)/60, \".3f\")\n","  str1 = f'Epoch: {epoch+1}/{EPOCHS} \\n'\n","  str2 = f'--------------------------------------------------------------------\\n'\n","  str3 = f'Training MAE: {format(train_mae, \".3f\")}\\n'\n","  str4 = f'Training_Cost: {format(cost, \".3f\")}\\n'\n","  str5 = f'Training_Acc: {training_acc}%\\n'\n","  str6 = f'Time elapsed: {time_elapsed}mins\\n'\n","\n","  str = str1+str2+str3+str4+str5+str6\n","  print(str)\n","  with open(LOGFILE, 'a') as f: f.write(f'{str}')\n","  \n","  model_name = f'Epoch_{epoch+1}_model.pt'\n","  torch.save(model.state_dict(), os.path.join(PATH, model_name)) # saving the model\n","  with open(LOGFILE, 'a') as f: f.write(f'---Model Saved---\\n')\n","  print(f'---Model Saved---\\n')\n","    \n","with open(LOGFILE, 'a') as f: f.write('\\n\\n############-------Training Completed-------############\\n\\n')\n","print(\"TRAINING COMPLETED\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DGLcsLm9G3eI"},"source":["**Evaluataion**"]},{"cell_type":"code","metadata":{"id":"0cvUz43eZ06O"},"source":["def compute_mae_and_mse(model, data_loader, device):\n","  mae, mse, num_examples, total_num_correct_preds = 0., 0., 0, 0\n","  for i, (features, targets, levels) in enumerate(data_loader):\n","          \n","    targets, features = targets.to(device), features.to(device)\n","    logits, probas = model(features)\n","    predict_levels = probas > 0.5\n","\n","    predicted_labels = torch.sum(predict_levels, dim=1)\n","    num_correct_preds = torch.sum(predicted_labels == targets)\n","    total_num_correct_preds += num_correct_preds\n","    num_examples += targets.size(0)\n","\n","    mae += torch.sum(torch.abs(predicted_labels - targets))\n","    mse += torch.sum((predicted_labels - targets)**2)\n","\n","  print(f'total_num_correct_preds: {total_num_correct_preds}')\n","  acc = compute_acc(total_num_correct_preds, num_examples)\n","  mae = format(mae.float()/num_examples, '.3f')\n","  mse = format(torch.sqrt(mse.float()/num_examples), '.3f')      \n","\n","  return mae, mse, acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnmB2e0NZ06O"},"source":["model.eval()\n","with torch.set_grad_enabled(False):  # save memory during inference\n","\n","  train_mae, train_mse, train_acc = compute_mae_and_mse(model, train_loader, device=DEVICE)\n","  str1 = f'Training MAE: {train_mae}\\n'\n","  str2 = f'Training RMSE: {train_mse}\\n'\n","  str3 = f'Training Acc: {train_acc}%\\n'\n","  str = str1+str2+str3\n","\n","  print(str)\n","  with open(LOGFILE, 'a') as f: f.write(f'{str}')\n","\n","str = f'Total Elapsed Time: {format(((time.time() - start_time)/60), \".3f\")} mins \\n'\n","print(str)\n","with open(LOGFILE, 'a') as f: f.write(f'{str}\\n')"],"execution_count":null,"outputs":[]}]}