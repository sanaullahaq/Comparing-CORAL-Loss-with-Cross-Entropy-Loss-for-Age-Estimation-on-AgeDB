{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UTK-CORAL-Age Classification.ipynb","provenance":[{"file_id":"1W_fU7WFJVg6JhJgMBWqS84W5I9DFUcbm","timestamp":1628873020680}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1sCSm1yBLam3","executionInfo":{"status":"ok","timestamp":1628870318076,"user_tz":-360,"elapsed":467,"user":{"displayName":"Iftekhar Ahmed Uday 1711859642","photoUrl":"","userId":"17360485868235920387"}},"outputId":"00fa9177-1461-43fd-b2c6-e6e76a379bdc"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fri Aug 13 15:58:44 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    61W / 149W |   3907MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eVYPkc9E3b10"},"source":["import os\n","import time\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import argparse\n","\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from torchvision import transforms\n","from PIL import Image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YVbXEcusLdzR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628871466728,"user_tz":-360,"elapsed":24072,"user":{"displayName":"Sanaulla Haq 1721380","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAkqAf_pb2GvyDutFhnvyO_vWqqbZkyyi_Lx85Rg=s64","userId":"10115064749693268524"}},"outputId":"59e37436-4f91-4d6b-8076-2ab34a327b83"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h-at6gKB9Y7-"},"source":["TRAIN_CSV_PATH = '/content/drive/MyDrive/CSE465_project/Age-Classification/datasets/utk_train.csv'\n","TEST_CSV_PATH = '/content/drive/MyDrive/CSE465_project/Age-Classification/datasets/utk_test.csv'\n","IMAGE_PATH = '/content/drive/MyDrive/CSE465_project/Age-Classification/images/UTKFace/'\n","\n","RANDOM_SEED = 42\n","\n","MODEL_NAME = \"UTK-CE_ResNet_100%\"\n","\n","PATH = \"/content/drive/MyDrive/CSE465_project/Models and Logs/\" + MODEL_NAME\n","\n","NUM_CLASSES = 40\n","\n","IMP_WEIGHT = 0\n","\n","BATCH_SIZE = 256\n","\n","GRAYSCALE = False\n","\n","learning_rate = 0.0005 #5e-4\n","\n","num_epochs = 200"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DWSmbJ3-FVo"},"source":["# GPU or CPU\n","if torch.cuda.is_available():\n","    DEVICE = torch.device('cuda')\n","else:\n","    DEVICE = torch.device('cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ues9nF1sCRB5"},"source":["# Log File\n","if not os.path.exists(PATH):\n","  os.mkdir(PATH)\n","LOGFILE = os.path.join(PATH, 'training.log')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-R-4BDObays5"},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvLgbCcoAzaT"},"source":["header = []\n","\n","header.append('PyTorch Version: %s' % torch.__version__)\n","header.append('CUDA device available: %s' % torch.cuda.is_available())\n","header.append('Using CUDA device: %s' % DEVICE)\n","header.append('Random Seed: %s' % RANDOM_SEED)\n","header.append('Task Importance Weight: %s' % IMP_WEIGHT)\n","header.append('Output Path: %s' % PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k58Rk4wpA0ZR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628865200001,"user_tz":-360,"elapsed":1443,"user":{"displayName":"Iftekhar Ahmed Uday 1711859642","photoUrl":"","userId":"17360485868235920387"}},"outputId":"0eb80861-24df-48f2-e36d-9148c5c3ec10"},"source":["with open(LOGFILE, 'w') as f:\n","    for entry in header:\n","        print(entry)\n","        f.write('%s\\n' % entry)\n","        f.flush()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PyTorch Version: 1.9.0+cu102\n","CUDA device available: True\n","Using CUDA device: cuda\n","Random Seed: 42\n","Output Path: /content/drive/MyDrive/CSE465_project/Models and Logs/UTK-CE_ResNet_100%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mjEDWKU6cCVx"},"source":["df = pd.read_csv(TRAIN_CSV_PATH, index_col=0)\n","ages = df['age'].values\n","del df\n","ages = torch.tensor(ages, dtype=torch.float)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NtQ3SyApbyou"},"source":["def task_importance_weights(label_array):\n","    uniq = torch.unique(label_array)\n","    num_examples = label_array.size(0)\n","\n","    m = torch.zeros(uniq.shape[0])\n","\n","    for i, t in enumerate(torch.arange(torch.min(uniq), torch.max(uniq))):\n","        m_k = torch.max(torch.tensor([label_array[label_array > t].size(0), \n","                                      num_examples - label_array[label_array > t].size(0)]))\n","        m[i] = torch.sqrt(m_k.float())\n","\n","    imp = m/torch.max(m)\n","    return imp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"baSlyhuhcFY5"},"source":["# Data-specific scheme\n","if not IMP_WEIGHT:\n","    imp = torch.ones(NUM_CLASSES-1, dtype=torch.float)\n","elif IMP_WEIGHT == 1:\n","    imp = task_importance_weights(ages)\n","    imp = imp[0:NUM_CLASSES-1]\n","else:\n","    raise ValueError('Incorrect importance weight parameter.')\n","imp = imp.to(DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sPMn1Hv7EM_y"},"source":["Dataset"]},{"cell_type":"code","metadata":{"id":"efWuaBb8CYi0"},"source":["class UTKFaceDataset(Dataset):\n","    \"\"\"Custom Dataset for loading UTKFace face images\"\"\"\n","\n","    def __init__(self,\n","                 csv_path, img_dir, transform=None, items=None):\n","\n","        df = pd.read_csv(csv_path, index_col=0)\n","        if items:\n","          df=df[:items]\n","        self.img_dir = img_dir\n","        self.csv_path = csv_path\n","        self.img_names = df['file'].values\n","        self.y = df['age'].values\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img = Image.open(os.path.join(self.img_dir,\n","                                      self.img_names[index]))\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        label = self.y[index]\n","        levels = [1]*label + [0]*(NUM_CLASSES - 1 - label)\n","        levels = torch.tensor(levels, dtype=torch.float32)\n","\n","        return img, label, levels\n","\n","    def __len__(self):\n","        return self.y.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7AuQwbC4EP33"},"source":["custom_transform = transforms.Compose([transforms.Resize((128, 128)),\n","                                       transforms.RandomCrop((120, 120)),\n","                                       transforms.ToTensor()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1bBY4dAEVId"},"source":["train_dataset = UTKFaceDataset(csv_path=TRAIN_CSV_PATH,\n","                               img_dir=IMAGE_PATH,\n","                               transform=custom_transform,\n","                               items=None\n","                              )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O92GTtSnEWjE"},"source":["custom_transform2 = transforms.Compose([transforms.Resize((128, 128)),\n","                                       transforms.CenterCrop((120, 120)),\n","                                       transforms.ToTensor()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Y9LieAKEXAB"},"source":["test_dataset = UTKFaceDataset(csv_path=TEST_CSV_PATH,\n","                              img_dir=IMAGE_PATH,\n","                              transform=custom_transform2,\n","                              items=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XEA8Xwg9EaPM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628865201056,"user_tz":-360,"elapsed":11,"user":{"displayName":"Iftekhar Ahmed Uday 1711859642","photoUrl":"","userId":"17360485868235920387"}},"outputId":"66d13de2-babb-49c8-a553-0c7240417108"},"source":["train_loader = DataLoader(dataset=train_dataset,\n","                          batch_size=BATCH_SIZE,\n","                          shuffle=True,\n","                          num_workers=4)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"LYm9CDLaEdTl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628865201056,"user_tz":-360,"elapsed":6,"user":{"displayName":"Iftekhar Ahmed Uday 1711859642","photoUrl":"","userId":"17360485868235920387"}},"outputId":"af2084bb-62bb-44ef-d3df-249afeab6be3"},"source":["test_loader = DataLoader(dataset=test_dataset,\n","                         batch_size=BATCH_SIZE,\n","                         shuffle=False,\n","                         num_workers=4)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ZdHzUfDDE-ss"},"source":["Model"]},{"cell_type":"code","metadata":{"id":"Ngh4foshFvlW"},"source":["def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dqPvkQ4jEfnU"},"source":["class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d86rbpd6EQgj"},"source":["`nn.RELU(inplace=True)` [details](https://discuss.pytorch.org/t/whats-the-difference-between-nn-relu-and-nn-relu-inplace-true/948)\n","\n","Understanding the underscore( _ ) of Python [link](https://stackoverflow.com/questions/8689964/why-do-some-functions-have-underscores-before-and-after-the-function-name)\n","\n","`self.modules()` [link](https://discuss.pytorch.org/t/pytorch-self-module/49677)\n","\n","What do `*` and `**` before a variable name mean in a function signature? [link](https://stackoverflow.com/questions/11315010/what-do-and-before-a-variable-name-mean-in-a-function-signature)"]},{"cell_type":"code","metadata":{"id":"pg2O85F2FJM4"},"source":["class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes, grayscale):\n","        self.num_classes = num_classes\n","        self.inplanes = 64\n","        if grayscale:\n","            in_dim = 1\n","        else:\n","            in_dim = 3\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        self.avgpool = nn.AvgPool2d(7, stride=1, padding=2)\n","        self.fc = nn.Linear(2048 * block.expansion, 1, bias=False)\n","        self.linear_1_bias = nn.Parameter(torch.zeros(self.num_classes-1).float())\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, (2. / n)**.5)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpool(x)\n","\n","        x = x.view(x.size(0), -1) # reshaping, -1 means calculate the suitable number for second dimension \n","        logits = self.fc(x)\n","        \n","        logits = logits + self.linear_1_bias\n","        probas = torch.sigmoid(logits)\n","\n","        return logits, probas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"al0QfP0WFcHQ"},"source":["def resnet34(num_classes, grayscale):\n","    \"\"\"Constructs a ResNet-34 model.\"\"\"\n","    model = ResNet(block=BasicBlock, \n","                   layers=[3, 4, 6, 3],\n","                   num_classes=num_classes,\n","                   grayscale=grayscale)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y_YE6EwzJtW8"},"source":["Initialize Cost, Model, and Optimizer"]},{"cell_type":"code","metadata":{"id":"6vDfpvsze0Fu"},"source":["def cost_fn(logits, levels, imp):\n","    val = (-torch.sum((F.logsigmoid(logits)*levels\n","                       + (F.logsigmoid(logits) - logits)*(1-levels))*imp,\n","                       dim=1))\t\n","    return torch.mean(val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZoIklH-mJxjo"},"source":["torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed(RANDOM_SEED)\n","model = resnet34(NUM_CLASSES, GRAYSCALE)\n","\n","model.to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o5dAKh0KJ9Uc"},"source":["# Training\n","\n","PyTorch Normally add the previously calculated gradient with the current calculated gradient and then updates the weight. But here we don't want it. That's why we made the previously calculted gradient zero while calculating a new one with `optimizer.zero_grad()`"]},{"cell_type":"code","metadata":{"id":"Szhycqs4J-pz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628869956547,"user_tz":-360,"elapsed":4229391,"user":{"displayName":"Iftekhar Ahmed Uday 1711859642","photoUrl":"","userId":"17360485868235920387"}},"outputId":"c506df67-e861-4fde-b162-218b171f505e"},"source":["start_time = time.time()\n","for epoch in range(num_epochs):\n","\n","    model.train()\n","    for batch_idx, (features, targets, levels) in enumerate(train_loader):\n","\n","        features = features.to(DEVICE)\n","        targets = targets\n","        targets = targets.to(DEVICE)\n","        levels = levels.to(DEVICE)\n","\n","        # FORWARD AND BACK PROP\n","        logits, probas = model(features)\n","        cost = cost_fn(logits, levels, imp)\n","        optimizer.zero_grad()\n","\n","        cost.backward()\n","\n","        # UPDATE MODEL PARAMETERS\n","        optimizer.step()\n","\n","        # LOGGING\n","        if not batch_idx % 50:\n","            s = ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f'\n","                 % (epoch+1, num_epochs, batch_idx,\n","                     len(train_dataset)//BATCH_SIZE, cost)) #the floor division // rounds the result down to the nearest whole number\n","            print(s)\n","            with open(LOGFILE, 'a') as f:\n","                f.write('%s\\n' % s)\n","\n","    s = 'Time elapsed: %.2f min' % ((time.time() - start_time)/60)\n","    print(s)\n","    with open(LOGFILE, 'a') as f:\n","        f.write('%s\\n' % s)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 001/200 | Batch 0000/0012 | Cost: 3.7365\n","Time elapsed: 4.42 min\n","Epoch: 002/200 | Batch 0000/0012 | Cost: 3.3004\n","Time elapsed: 4.75 min\n","Epoch: 003/200 | Batch 0000/0012 | Cost: 3.1646\n","Time elapsed: 5.08 min\n","Epoch: 004/200 | Batch 0000/0012 | Cost: 3.1745\n","Time elapsed: 5.41 min\n","Epoch: 005/200 | Batch 0000/0012 | Cost: 3.1141\n","Time elapsed: 5.75 min\n","Epoch: 006/200 | Batch 0000/0012 | Cost: 2.9782\n","Time elapsed: 6.08 min\n","Epoch: 007/200 | Batch 0000/0012 | Cost: 2.8564\n","Time elapsed: 6.41 min\n","Epoch: 008/200 | Batch 0000/0012 | Cost: 2.7422\n","Time elapsed: 6.74 min\n","Epoch: 009/200 | Batch 0000/0012 | Cost: 2.6668\n","Time elapsed: 7.07 min\n","Epoch: 010/200 | Batch 0000/0012 | Cost: 2.3167\n","Time elapsed: 7.40 min\n","Epoch: 011/200 | Batch 0000/0012 | Cost: 2.1863\n","Time elapsed: 7.73 min\n","Epoch: 012/200 | Batch 0000/0012 | Cost: 1.8494\n","Time elapsed: 8.06 min\n","Epoch: 013/200 | Batch 0000/0012 | Cost: 1.6492\n","Time elapsed: 8.40 min\n","Epoch: 014/200 | Batch 0000/0012 | Cost: 1.4317\n","Time elapsed: 8.73 min\n","Epoch: 015/200 | Batch 0000/0012 | Cost: 1.3407\n","Time elapsed: 9.06 min\n","Epoch: 016/200 | Batch 0000/0012 | Cost: 1.0936\n","Time elapsed: 9.39 min\n","Epoch: 017/200 | Batch 0000/0012 | Cost: 0.8496\n","Time elapsed: 9.72 min\n","Epoch: 018/200 | Batch 0000/0012 | Cost: 0.6881\n","Time elapsed: 10.05 min\n","Epoch: 019/200 | Batch 0000/0012 | Cost: 0.5445\n","Time elapsed: 10.39 min\n","Epoch: 020/200 | Batch 0000/0012 | Cost: 0.4407\n","Time elapsed: 10.72 min\n","Epoch: 021/200 | Batch 0000/0012 | Cost: 0.4022\n","Time elapsed: 11.05 min\n","Epoch: 022/200 | Batch 0000/0012 | Cost: 0.2260\n","Time elapsed: 11.39 min\n","Epoch: 023/200 | Batch 0000/0012 | Cost: 0.2910\n","Time elapsed: 11.72 min\n","Epoch: 024/200 | Batch 0000/0012 | Cost: 0.1785\n","Time elapsed: 12.05 min\n","Epoch: 025/200 | Batch 0000/0012 | Cost: 0.2391\n","Time elapsed: 12.38 min\n","Epoch: 026/200 | Batch 0000/0012 | Cost: 0.1509\n","Time elapsed: 12.71 min\n","Epoch: 027/200 | Batch 0000/0012 | Cost: 0.1813\n","Time elapsed: 13.04 min\n","Epoch: 028/200 | Batch 0000/0012 | Cost: 0.1380\n","Time elapsed: 13.37 min\n","Epoch: 029/200 | Batch 0000/0012 | Cost: 0.0880\n","Time elapsed: 13.70 min\n","Epoch: 030/200 | Batch 0000/0012 | Cost: 0.0984\n","Time elapsed: 14.04 min\n","Epoch: 031/200 | Batch 0000/0012 | Cost: 0.0889\n","Time elapsed: 14.37 min\n","Epoch: 032/200 | Batch 0000/0012 | Cost: 0.0583\n","Time elapsed: 14.70 min\n","Epoch: 033/200 | Batch 0000/0012 | Cost: 0.0354\n","Time elapsed: 15.03 min\n","Epoch: 034/200 | Batch 0000/0012 | Cost: 0.0536\n","Time elapsed: 15.36 min\n","Epoch: 035/200 | Batch 0000/0012 | Cost: 0.0424\n","Time elapsed: 15.69 min\n","Epoch: 036/200 | Batch 0000/0012 | Cost: 0.0788\n","Time elapsed: 16.02 min\n","Epoch: 037/200 | Batch 0000/0012 | Cost: 0.0617\n","Time elapsed: 16.35 min\n","Epoch: 038/200 | Batch 0000/0012 | Cost: 0.0481\n","Time elapsed: 16.68 min\n","Epoch: 039/200 | Batch 0000/0012 | Cost: 0.0711\n","Time elapsed: 17.01 min\n","Epoch: 040/200 | Batch 0000/0012 | Cost: 0.0908\n","Time elapsed: 17.35 min\n","Epoch: 041/200 | Batch 0000/0012 | Cost: 0.0769\n","Time elapsed: 17.68 min\n","Epoch: 042/200 | Batch 0000/0012 | Cost: 0.1273\n","Time elapsed: 18.01 min\n","Epoch: 043/200 | Batch 0000/0012 | Cost: 0.0739\n","Time elapsed: 18.35 min\n","Epoch: 044/200 | Batch 0000/0012 | Cost: 0.1014\n","Time elapsed: 18.68 min\n","Epoch: 045/200 | Batch 0000/0012 | Cost: 0.1047\n","Time elapsed: 19.01 min\n","Epoch: 046/200 | Batch 0000/0012 | Cost: 0.1417\n","Time elapsed: 19.35 min\n","Epoch: 047/200 | Batch 0000/0012 | Cost: 0.1000\n","Time elapsed: 19.68 min\n","Epoch: 048/200 | Batch 0000/0012 | Cost: 0.1002\n","Time elapsed: 20.01 min\n","Epoch: 049/200 | Batch 0000/0012 | Cost: 0.0836\n","Time elapsed: 20.35 min\n","Epoch: 050/200 | Batch 0000/0012 | Cost: 0.1160\n","Time elapsed: 20.68 min\n","Epoch: 051/200 | Batch 0000/0012 | Cost: 0.1074\n","Time elapsed: 21.01 min\n","Epoch: 052/200 | Batch 0000/0012 | Cost: 0.0587\n","Time elapsed: 21.34 min\n","Epoch: 053/200 | Batch 0000/0012 | Cost: 0.0790\n","Time elapsed: 21.67 min\n","Epoch: 054/200 | Batch 0000/0012 | Cost: 0.0901\n","Time elapsed: 22.01 min\n","Epoch: 055/200 | Batch 0000/0012 | Cost: 0.0566\n","Time elapsed: 22.34 min\n","Epoch: 056/200 | Batch 0000/0012 | Cost: 0.0647\n","Time elapsed: 22.67 min\n","Epoch: 057/200 | Batch 0000/0012 | Cost: 0.0381\n","Time elapsed: 23.01 min\n","Epoch: 058/200 | Batch 0000/0012 | Cost: 0.0885\n","Time elapsed: 23.34 min\n","Epoch: 059/200 | Batch 0000/0012 | Cost: 0.0407\n","Time elapsed: 23.67 min\n","Epoch: 060/200 | Batch 0000/0012 | Cost: 0.0674\n","Time elapsed: 24.00 min\n","Epoch: 061/200 | Batch 0000/0012 | Cost: 0.0561\n","Time elapsed: 24.33 min\n","Epoch: 062/200 | Batch 0000/0012 | Cost: 0.0249\n","Time elapsed: 24.67 min\n","Epoch: 063/200 | Batch 0000/0012 | Cost: 0.0939\n","Time elapsed: 25.00 min\n","Epoch: 064/200 | Batch 0000/0012 | Cost: 0.0573\n","Time elapsed: 25.33 min\n","Epoch: 065/200 | Batch 0000/0012 | Cost: 0.0313\n","Time elapsed: 25.66 min\n","Epoch: 066/200 | Batch 0000/0012 | Cost: 0.0940\n","Time elapsed: 25.99 min\n","Epoch: 067/200 | Batch 0000/0012 | Cost: 0.0247\n","Time elapsed: 26.33 min\n","Epoch: 068/200 | Batch 0000/0012 | Cost: 0.0279\n","Time elapsed: 26.66 min\n","Epoch: 069/200 | Batch 0000/0012 | Cost: 0.0675\n","Time elapsed: 27.00 min\n","Epoch: 070/200 | Batch 0000/0012 | Cost: 0.0406\n","Time elapsed: 27.33 min\n","Epoch: 071/200 | Batch 0000/0012 | Cost: 0.0206\n","Time elapsed: 27.66 min\n","Epoch: 072/200 | Batch 0000/0012 | Cost: 0.0284\n","Time elapsed: 27.99 min\n","Epoch: 073/200 | Batch 0000/0012 | Cost: 0.0553\n","Time elapsed: 28.33 min\n","Epoch: 074/200 | Batch 0000/0012 | Cost: 0.0269\n","Time elapsed: 28.66 min\n","Epoch: 075/200 | Batch 0000/0012 | Cost: 0.0233\n","Time elapsed: 29.00 min\n","Epoch: 076/200 | Batch 0000/0012 | Cost: 0.0511\n","Time elapsed: 29.33 min\n","Epoch: 077/200 | Batch 0000/0012 | Cost: 0.0139\n","Time elapsed: 29.67 min\n","Epoch: 078/200 | Batch 0000/0012 | Cost: 0.0279\n","Time elapsed: 30.01 min\n","Epoch: 079/200 | Batch 0000/0012 | Cost: 0.0550\n","Time elapsed: 30.34 min\n","Epoch: 080/200 | Batch 0000/0012 | Cost: 0.0588\n","Time elapsed: 30.68 min\n","Epoch: 081/200 | Batch 0000/0012 | Cost: 0.0129\n","Time elapsed: 31.02 min\n","Epoch: 082/200 | Batch 0000/0012 | Cost: 0.0466\n","Time elapsed: 31.35 min\n","Epoch: 083/200 | Batch 0000/0012 | Cost: 0.0150\n","Time elapsed: 31.69 min\n","Epoch: 084/200 | Batch 0000/0012 | Cost: 0.0231\n","Time elapsed: 32.03 min\n","Epoch: 085/200 | Batch 0000/0012 | Cost: 0.0479\n","Time elapsed: 32.36 min\n","Epoch: 086/200 | Batch 0000/0012 | Cost: 0.0296\n","Time elapsed: 32.70 min\n","Epoch: 087/200 | Batch 0000/0012 | Cost: 0.0491\n","Time elapsed: 33.04 min\n","Epoch: 088/200 | Batch 0000/0012 | Cost: 0.0367\n","Time elapsed: 33.37 min\n","Epoch: 089/200 | Batch 0000/0012 | Cost: 0.0159\n","Time elapsed: 33.71 min\n","Epoch: 090/200 | Batch 0000/0012 | Cost: 0.0188\n","Time elapsed: 34.04 min\n","Epoch: 091/200 | Batch 0000/0012 | Cost: 0.0074\n","Time elapsed: 34.38 min\n","Epoch: 092/200 | Batch 0000/0012 | Cost: 0.0322\n","Time elapsed: 34.71 min\n","Epoch: 093/200 | Batch 0000/0012 | Cost: 0.0208\n","Time elapsed: 35.04 min\n","Epoch: 094/200 | Batch 0000/0012 | Cost: 0.0351\n","Time elapsed: 35.37 min\n","Epoch: 095/200 | Batch 0000/0012 | Cost: 0.0308\n","Time elapsed: 35.71 min\n","Epoch: 096/200 | Batch 0000/0012 | Cost: 0.0326\n","Time elapsed: 36.04 min\n","Epoch: 097/200 | Batch 0000/0012 | Cost: 0.0592\n","Time elapsed: 36.37 min\n","Epoch: 098/200 | Batch 0000/0012 | Cost: 0.0207\n","Time elapsed: 36.71 min\n","Epoch: 099/200 | Batch 0000/0012 | Cost: 0.0653\n","Time elapsed: 37.03 min\n","Epoch: 100/200 | Batch 0000/0012 | Cost: 0.0385\n","Time elapsed: 37.36 min\n","Epoch: 101/200 | Batch 0000/0012 | Cost: 0.0431\n","Time elapsed: 37.69 min\n","Epoch: 102/200 | Batch 0000/0012 | Cost: 0.0872\n","Time elapsed: 38.02 min\n","Epoch: 103/200 | Batch 0000/0012 | Cost: 0.0488\n","Time elapsed: 38.36 min\n","Epoch: 104/200 | Batch 0000/0012 | Cost: 0.0528\n","Time elapsed: 38.69 min\n","Epoch: 105/200 | Batch 0000/0012 | Cost: 0.0641\n","Time elapsed: 39.02 min\n","Epoch: 106/200 | Batch 0000/0012 | Cost: 0.0898\n","Time elapsed: 39.35 min\n","Epoch: 107/200 | Batch 0000/0012 | Cost: 0.1942\n","Time elapsed: 39.68 min\n","Epoch: 108/200 | Batch 0000/0012 | Cost: 0.1204\n","Time elapsed: 40.01 min\n","Epoch: 109/200 | Batch 0000/0012 | Cost: 0.0886\n","Time elapsed: 40.34 min\n","Epoch: 110/200 | Batch 0000/0012 | Cost: 0.1788\n","Time elapsed: 40.67 min\n","Epoch: 111/200 | Batch 0000/0012 | Cost: 0.1732\n","Time elapsed: 41.01 min\n","Epoch: 112/200 | Batch 0000/0012 | Cost: 0.1241\n","Time elapsed: 41.34 min\n","Epoch: 113/200 | Batch 0000/0012 | Cost: 0.1065\n","Time elapsed: 41.67 min\n","Epoch: 114/200 | Batch 0000/0012 | Cost: 0.0917\n","Time elapsed: 42.00 min\n","Epoch: 115/200 | Batch 0000/0012 | Cost: 0.0273\n","Time elapsed: 42.33 min\n","Epoch: 116/200 | Batch 0000/0012 | Cost: 0.0215\n","Time elapsed: 42.66 min\n","Epoch: 117/200 | Batch 0000/0012 | Cost: 0.0432\n","Time elapsed: 43.00 min\n","Epoch: 118/200 | Batch 0000/0012 | Cost: 0.0165\n","Time elapsed: 43.33 min\n","Epoch: 119/200 | Batch 0000/0012 | Cost: 0.0400\n","Time elapsed: 43.67 min\n","Epoch: 120/200 | Batch 0000/0012 | Cost: 0.0218\n","Time elapsed: 44.00 min\n","Epoch: 121/200 | Batch 0000/0012 | Cost: 0.0899\n","Time elapsed: 44.33 min\n","Epoch: 122/200 | Batch 0000/0012 | Cost: 0.0252\n","Time elapsed: 44.66 min\n","Epoch: 123/200 | Batch 0000/0012 | Cost: 0.0101\n","Time elapsed: 45.00 min\n","Epoch: 124/200 | Batch 0000/0012 | Cost: 0.0149\n","Time elapsed: 45.33 min\n","Epoch: 125/200 | Batch 0000/0012 | Cost: 0.0063\n","Time elapsed: 45.66 min\n","Epoch: 126/200 | Batch 0000/0012 | Cost: 0.0103\n","Time elapsed: 45.99 min\n","Epoch: 127/200 | Batch 0000/0012 | Cost: 0.0101\n","Time elapsed: 46.33 min\n","Epoch: 128/200 | Batch 0000/0012 | Cost: 0.0105\n","Time elapsed: 46.66 min\n","Epoch: 129/200 | Batch 0000/0012 | Cost: 0.0067\n","Time elapsed: 46.99 min\n","Epoch: 130/200 | Batch 0000/0012 | Cost: 0.0030\n","Time elapsed: 47.32 min\n","Epoch: 131/200 | Batch 0000/0012 | Cost: 0.0295\n","Time elapsed: 47.65 min\n","Epoch: 132/200 | Batch 0000/0012 | Cost: 0.0234\n","Time elapsed: 47.98 min\n","Epoch: 133/200 | Batch 0000/0012 | Cost: 0.0168\n","Time elapsed: 48.31 min\n","Epoch: 134/200 | Batch 0000/0012 | Cost: 0.0016\n","Time elapsed: 48.64 min\n","Epoch: 135/200 | Batch 0000/0012 | Cost: 0.0221\n","Time elapsed: 48.97 min\n","Epoch: 136/200 | Batch 0000/0012 | Cost: 0.0434\n","Time elapsed: 49.31 min\n","Epoch: 137/200 | Batch 0000/0012 | Cost: 0.0038\n","Time elapsed: 49.64 min\n","Epoch: 138/200 | Batch 0000/0012 | Cost: 0.0252\n","Time elapsed: 49.97 min\n","Epoch: 139/200 | Batch 0000/0012 | Cost: 0.0209\n","Time elapsed: 50.30 min\n","Epoch: 140/200 | Batch 0000/0012 | Cost: 0.0321\n","Time elapsed: 50.63 min\n","Epoch: 141/200 | Batch 0000/0012 | Cost: 0.0065\n","Time elapsed: 50.96 min\n","Epoch: 142/200 | Batch 0000/0012 | Cost: 0.0139\n","Time elapsed: 51.29 min\n","Epoch: 143/200 | Batch 0000/0012 | Cost: 0.0100\n","Time elapsed: 51.63 min\n","Epoch: 144/200 | Batch 0000/0012 | Cost: 0.0058\n","Time elapsed: 51.96 min\n","Epoch: 145/200 | Batch 0000/0012 | Cost: 0.0073\n","Time elapsed: 52.29 min\n","Epoch: 146/200 | Batch 0000/0012 | Cost: 0.0054\n","Time elapsed: 52.62 min\n","Epoch: 147/200 | Batch 0000/0012 | Cost: 0.0061\n","Time elapsed: 52.95 min\n","Epoch: 148/200 | Batch 0000/0012 | Cost: 0.0090\n","Time elapsed: 53.28 min\n","Epoch: 149/200 | Batch 0000/0012 | Cost: 0.0030\n","Time elapsed: 53.61 min\n","Epoch: 150/200 | Batch 0000/0012 | Cost: 0.0037\n","Time elapsed: 53.94 min\n","Epoch: 151/200 | Batch 0000/0012 | Cost: 0.0099\n","Time elapsed: 54.27 min\n","Epoch: 152/200 | Batch 0000/0012 | Cost: 0.0017\n","Time elapsed: 54.60 min\n","Epoch: 153/200 | Batch 0000/0012 | Cost: 0.0038\n","Time elapsed: 54.94 min\n","Epoch: 154/200 | Batch 0000/0012 | Cost: 0.0115\n","Time elapsed: 55.26 min\n","Epoch: 155/200 | Batch 0000/0012 | Cost: 0.0025\n","Time elapsed: 55.59 min\n","Epoch: 156/200 | Batch 0000/0012 | Cost: 0.0006\n","Time elapsed: 55.92 min\n","Epoch: 157/200 | Batch 0000/0012 | Cost: 0.0036\n","Time elapsed: 56.25 min\n","Epoch: 158/200 | Batch 0000/0012 | Cost: 0.0035\n","Time elapsed: 56.59 min\n","Epoch: 159/200 | Batch 0000/0012 | Cost: 0.0010\n","Time elapsed: 56.92 min\n","Epoch: 160/200 | Batch 0000/0012 | Cost: 0.0080\n","Time elapsed: 57.25 min\n","Epoch: 161/200 | Batch 0000/0012 | Cost: 0.0060\n","Time elapsed: 57.58 min\n","Epoch: 162/200 | Batch 0000/0012 | Cost: 0.0006\n","Time elapsed: 57.91 min\n","Epoch: 163/200 | Batch 0000/0012 | Cost: 0.0039\n","Time elapsed: 58.24 min\n","Epoch: 164/200 | Batch 0000/0012 | Cost: 0.0173\n","Time elapsed: 58.57 min\n","Epoch: 165/200 | Batch 0000/0012 | Cost: 0.0025\n","Time elapsed: 58.90 min\n","Epoch: 166/200 | Batch 0000/0012 | Cost: 0.0222\n","Time elapsed: 59.24 min\n","Epoch: 167/200 | Batch 0000/0012 | Cost: 0.0249\n","Time elapsed: 59.57 min\n","Epoch: 168/200 | Batch 0000/0012 | Cost: 0.0060\n","Time elapsed: 59.90 min\n","Epoch: 169/200 | Batch 0000/0012 | Cost: 0.0031\n","Time elapsed: 60.23 min\n","Epoch: 170/200 | Batch 0000/0012 | Cost: 0.0060\n","Time elapsed: 60.56 min\n","Epoch: 171/200 | Batch 0000/0012 | Cost: 0.0036\n","Time elapsed: 60.89 min\n","Epoch: 172/200 | Batch 0000/0012 | Cost: 0.0101\n","Time elapsed: 61.22 min\n","Epoch: 173/200 | Batch 0000/0012 | Cost: 0.0117\n","Time elapsed: 61.55 min\n","Epoch: 174/200 | Batch 0000/0012 | Cost: 0.0635\n","Time elapsed: 61.88 min\n","Epoch: 175/200 | Batch 0000/0012 | Cost: 0.0350\n","Time elapsed: 62.21 min\n","Epoch: 176/200 | Batch 0000/0012 | Cost: 0.1479\n","Time elapsed: 62.54 min\n","Epoch: 177/200 | Batch 0000/0012 | Cost: 0.2144\n","Time elapsed: 62.87 min\n","Epoch: 178/200 | Batch 0000/0012 | Cost: 0.1709\n","Time elapsed: 63.21 min\n","Epoch: 179/200 | Batch 0000/0012 | Cost: 0.2469\n","Time elapsed: 63.54 min\n","Epoch: 180/200 | Batch 0000/0012 | Cost: 0.2925\n","Time elapsed: 63.87 min\n","Epoch: 181/200 | Batch 0000/0012 | Cost: 0.1230\n","Time elapsed: 64.20 min\n","Epoch: 182/200 | Batch 0000/0012 | Cost: 0.1502\n","Time elapsed: 64.53 min\n","Epoch: 183/200 | Batch 0000/0012 | Cost: 0.1076\n","Time elapsed: 64.86 min\n","Epoch: 184/200 | Batch 0000/0012 | Cost: 0.1192\n","Time elapsed: 65.19 min\n","Epoch: 185/200 | Batch 0000/0012 | Cost: 0.0315\n","Time elapsed: 65.52 min\n","Epoch: 186/200 | Batch 0000/0012 | Cost: 0.0393\n","Time elapsed: 65.85 min\n","Epoch: 187/200 | Batch 0000/0012 | Cost: 0.0561\n","Time elapsed: 66.18 min\n","Epoch: 188/200 | Batch 0000/0012 | Cost: 0.0220\n","Time elapsed: 66.51 min\n","Epoch: 189/200 | Batch 0000/0012 | Cost: 0.0210\n","Time elapsed: 66.84 min\n","Epoch: 190/200 | Batch 0000/0012 | Cost: 0.0303\n","Time elapsed: 67.17 min\n","Epoch: 191/200 | Batch 0000/0012 | Cost: 0.0268\n","Time elapsed: 67.51 min\n","Epoch: 192/200 | Batch 0000/0012 | Cost: 0.0222\n","Time elapsed: 67.83 min\n","Epoch: 193/200 | Batch 0000/0012 | Cost: 0.0137\n","Time elapsed: 68.17 min\n","Epoch: 194/200 | Batch 0000/0012 | Cost: 0.0126\n","Time elapsed: 68.50 min\n","Epoch: 195/200 | Batch 0000/0012 | Cost: 0.0070\n","Time elapsed: 68.83 min\n","Epoch: 196/200 | Batch 0000/0012 | Cost: 0.0025\n","Time elapsed: 69.16 min\n","Epoch: 197/200 | Batch 0000/0012 | Cost: 0.0164\n","Time elapsed: 69.49 min\n","Epoch: 198/200 | Batch 0000/0012 | Cost: 0.0080\n","Time elapsed: 69.82 min\n","Epoch: 199/200 | Batch 0000/0012 | Cost: 0.0160\n","Time elapsed: 70.16 min\n","Epoch: 200/200 | Batch 0000/0012 | Cost: 0.0057\n","Time elapsed: 70.49 min\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pqN7eRujKRVs"},"source":["Evaluation"]},{"cell_type":"code","metadata":{"id":"DNPi0qwQKPmR"},"source":["def compute_mae_and_mse(model, data_loader, device):\n","    mae, mse, num_examples = 0., 0., 0\n","    for i, (features, targets, levels) in enumerate(data_loader):\n","            \n","        features = features.to(device)\n","        targets = targets.to(device)\n","\n","        logits, probas = model(features)\n","        predict_levels = probas > 0.5\n","\n","        predicted_labels = torch.sum(predict_levels, dim=1)\n","        \n","        num_examples += targets.size(0)\n","        mae += torch.sum(torch.abs(predicted_labels - targets))\n","        mse += torch.sum((predicted_labels - targets)**2)\n","    \n","    mae = mae.float()/num_examples\n","    mse = mse.float()/num_examples\n","       \n","    return mae, mse"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FaGcrkG9LC0E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628869973638,"user_tz":-360,"elapsed":17107,"user":{"displayName":"Iftekhar Ahmed Uday 1711859642","photoUrl":"","userId":"17360485868235920387"}},"outputId":"05dd6f9a-8cd3-46e4-e24e-58bbda44fc71"},"source":["model.eval()\n","with torch.set_grad_enabled(False):  # save memory during inference\n","\n","    train_mae, train_mse = compute_mae_and_mse(model, train_loader,\n","                                               device=DEVICE)\n","    test_mae, test_mse = compute_mae_and_mse(model, test_loader,\n","                                             device=DEVICE)\n","\n","    s = 'MAE/RMSE: | Train: %.2f/%.2f | Test: %.2f/%.2f' % (\n","        train_mae, torch.sqrt(train_mse), test_mae, torch.sqrt(test_mse))\n","    print(s)\n","    with open(LOGFILE, 'a') as f:\n","        f.write('%s\\n' % s)\n","\n","s = 'Total Training Time: %.2f min' % ((time.time() - start_time)/60)\n","print(s)\n","with open(LOGFILE, 'a') as f:\n","    f.write('%s\\n' % s)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["MAE/RMSE: | Train: 0.01/0.17 | Test: 0.01/0.20\n","Total Training Time: 70.78 min\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S4GoNs5KLPFq"},"source":["# Saving the Model\n","\n","PyTorch: What's the difference between state_dict and parameters()? [link](https://stackoverflow.com/questions/54746829/pytorch-whats-the-difference-between-state-dict-and-parameters)"]},{"cell_type":"code","metadata":{"id":"TIo42yI8LUKO"},"source":["model = model.to(torch.device('cpu'))\n","torch.save(model.state_dict(), os.path.join(PATH, 'model.pt'))"],"execution_count":null,"outputs":[]}]}